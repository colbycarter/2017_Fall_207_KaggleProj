{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Julia sample code\n",
    "using DataFrames\n",
    "using MachineLearning\n",
    "using JSON\n",
    "\n",
    "function read_data(file_name)\n",
    "    f = open(file_name)\n",
    "    json = JSON.parse(readall(f))\n",
    "    close(f)\n",
    "\n",
    "    colnames = keys(json[1])\n",
    "    columns  = Any[[json[i][name] for i=1:length(json)] for name=colnames]\n",
    "    DataFrame(columns, Symbol[name for name=colnames])\n",
    "end\n",
    "\n",
    "train = read_data(\"../data/train.json\")\n",
    "test  = read_data(\"../data/test.json\")\n",
    "\n",
    "println(@sprintf(\"There are %d rows in the training set\", nrow(train)))\n",
    "println(@sprintf(\"There are %d rows in the test set\", nrow(test)))\n",
    "\n",
    "feature_names = Symbol[\"requester_account_age_in_days_at_request\",\n",
    "                       \"requester_days_since_first_post_on_raop_at_request\",\n",
    "                       \"requester_number_of_comments_at_request\",\n",
    "                       \"requester_number_of_comments_in_raop_at_request\",\n",
    "                       \"requester_number_of_posts_at_request\",\n",
    "                       \"requester_number_of_posts_on_raop_at_request\",\n",
    "                       \"requester_number_of_subreddits_at_request\",\n",
    "                       \"requester_upvotes_minus_downvotes_at_request\",\n",
    "                       \"requester_upvotes_plus_downvotes_at_request\",\n",
    "                       \"unix_timestamp_of_request_utc\"]\n",
    "\n",
    "for feature = feature_names\n",
    "    train[feature] = float64(train[feature])\n",
    "    test[feature]  = float64(test[feature])\n",
    "end\n",
    "\n",
    "columns_to_keep = cat(1, feature_names, [:requester_received_pizza])\n",
    "\n",
    "rf = fit(train[columns_to_keep], :requester_received_pizza, classification_forest_options(num_trees=200, display=true))\n",
    "println(\"\")\n",
    "println(rf)\n",
    "println(\"\")\n",
    "predictions = predict_probs(rf, test)[:,2]\n",
    "submission = DataFrame(request_id=test[:request_id], requester_received_pizza=predictions)\n",
    "writetable(\"simple_julia_benchmark.csv\", submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3636, 31)\n",
      "(3636,)\n",
      "(1631, 17)\n",
      "(404, 31)\n",
      "['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_data  = pd.read_json('./data/train.json')\n",
    "train_labels = train_data['requester_received_pizza']\n",
    "train_data = train_data.drop('requester_received_pizza', 1)\n",
    "dev_size = int(train_data.shape[0]*.1)\n",
    "\n",
    "train_data, train_labels  = train_data[dev_size:], train_labels[dev_size:]\n",
    "dev_data, dev_labels = train_data[:dev_size], train_labels[:dev_size]\n",
    "\n",
    "names = list(train_data.columns.values)\n",
    "\n",
    "test_data  = pd.read_json('./data/test.json')\n",
    "#test_label = test_data['requester_received_pizza']\n",
    "#test_data = test_data.drop('requester_received_pizza', 1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(dev_data.shape)\n",
    "#print(test_label.shape)\n",
    "print(list(test_data.columns.values))\n",
    "print(dev_size)\n",
    "#print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Here we split the number variables from the object or string type variables\n",
    "obj_columns = ['giver_username_if_known','request_id','request_text','request_text_edit_aware','request_title',\n",
    "              'requester_subreddits_at_request','requester_user_flair','requester_username']\n",
    "num_columns = [i for i in names if i not in obj_columns]\n",
    "\n",
    "#Here we split the test data columns into\n",
    "test_names = list(test_data.columns.values)\n",
    "test_num_columns = [i for i in test_names if i not in obj_columns]\n",
    "test_obj_columns = [i for i in test_names if i not in test_num_columns]\n",
    "\n",
    "print(len(test_num_columns))\n",
    "print(len(test_obj_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631,)\n",
      "<class 'numpy.ndarray'>\n",
      "0 894\n"
     ]
    }
   ],
   "source": [
    "#Build an initial model based on number value columns\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(train_data[test_num_columns], train_labels)\n",
    "\n",
    "y_pred = lr.predict(test_data[test_num_columns])\n",
    "print(y_pred.shape)\n",
    "print(type(y_pred))\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "preds['request_id'] = test_data['request_id']\n",
    "preds['requester_received_pizza'] = y_pred.astype(int)\n",
    "num = sum(preds['requester_received_pizza'])\n",
    "\n",
    "print(num, sum(train_labels))\n",
    "\n",
    "preds.to_csv('./data/submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631,)\n",
      "<class 'numpy.ndarray'>\n",
      "0 894\n"
     ]
    }
   ],
   "source": [
    "#Normalized Dataframe\n",
    "num_train_data = pd.DataFrame()\n",
    "\n",
    "for column in train_data[test_num_columns]:\n",
    "    num_train_data[column] = (train_data[column]-train_data[column].mean())/ train_data[column].std()\n",
    "    \n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(num_train_data, train_labels)\n",
    "\n",
    "y_pred = lr.predict(test_data[test_num_columns])\n",
    "print(y_pred.shape)\n",
    "print(type(y_pred))\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "preds['request_id'] = test_data['request_id']\n",
    "preds['requester_received_pizza'] = y_pred.astype(int)\n",
    "num = sum(preds['requester_received_pizza'])\n",
    "\n",
    "print(num, sum(train_labels))\n",
    "\n",
    "preds.to_csv('./data/submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631,)\n",
      "<class 'numpy.ndarray'>\n",
      "81 894\n"
     ]
    }
   ],
   "source": [
    "#Try looking at request only\n",
    "train_req = train_data['request_text_edit_aware']\n",
    "test_req = test_data['request_text_edit_aware']\n",
    "vec = CountVectorizer()\n",
    "train = vec.fit_transform(train_req)\n",
    "vocab_train = vec.get_feature_names()\n",
    "vec2 = CountVectorizer(vocabulary=vocab_train)\n",
    "test = vec2.fit_transform(test_req)\n",
    "\n",
    "mb =  MultinomialNB()\n",
    "mb.fit(train, train_labels)\n",
    "y_pred = mb.predict(test)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(type(y_pred))\n",
    "\n",
    "preds = pd.DataFrame()\n",
    "preds['request_id'] = test_data['request_id']\n",
    "preds['requester_received_pizza'] = y_pred.astype(int)\n",
    "num = sum(preds['requester_received_pizza'])\n",
    "\n",
    "print(num, sum(train_labels))\n",
    "\n",
    "preds.to_csv('./data/submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
